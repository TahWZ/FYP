{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========== IMPORTS =============#\n",
    "# Allows jupyter notebook to be imported\n",
    "import jupyter_import\n",
    "from data_preproc.Preprocess import preprocess\n",
    "#================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preproc.CFS import cfs_algo\n",
    "from data_preproc.RFE import rfe_algo\n",
    "from data_preproc.RR import ridge_algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pred_mdls.base.Complement_Naive_Bayes import complement_naive_bayes_model\n",
    "from pred_mdls.base.Decision_Tree import decision_tree_model\n",
    "from pred_mdls.base.Logistic_Regression import logistic_regression_model\n",
    "from pred_mdls.base.Multi_Layer_Perceptron import multi_layer_perceptron_model\n",
    "from pred_mdls.base.Naive_Bayes import naive_bayes_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pred_mdls.ensemble.Random_Forest import random_forest_model\n",
    "from pred_mdls.ensemble.Rotation_Forest import rotation_forest_model\n",
    "from pred_mdls.ensemble.Voting import voting_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Feature      Score\n",
      "27             MAINTENANCE_SEVERITY  33.127413\n",
      "2                        CALL_PAIRS  22.088178\n",
      "31  NORMALIZED_CYLOMATIC_COMPLEXITY  15.380972\n",
      "11                   DESIGN_DENSITY  11.439184\n",
      "30                       NODE_COUNT   7.730448\n",
      "12                       EDGE_COUNT   7.669434\n",
      "1                      BRANCH_COUNT   7.149434\n",
      "6             CYCLOMATIC_COMPLEXITY   7.149434\n",
      "10                DESIGN_COMPLEXITY   6.595051\n",
      "13             ESSENTIAL_COMPLEXITY   1.114354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: UserWarning: Features [ 0  3  4  5  8  9 15 16 17 18 19 20 21 22 23 24 25 26 28 29 32 33 34 35\n",
      " 37 38] are constant.\n",
      "  UserWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_features_to_select=3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'ranking_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f760e03558a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'KC4.arff.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-f760e03558a7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# ===== RFE ======== #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe_algo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# software_metrics,labels = process_data(loaddata,features)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'ranking_'"
     ]
    }
   ],
   "source": [
    "def data_conversion(data):\n",
    "    for i in range(len(data)):\n",
    "        if data[i] == b'N':\n",
    "            data[i] = 0\n",
    "        else:\n",
    "            data[i] = 1\n",
    "    return data\n",
    "\n",
    "def read_data(filename):\n",
    "    data = arff.loadarff(filename)\n",
    "    loaddata = pd.DataFrame(data[0])\n",
    "    return loaddata\n",
    "\n",
    "def process_data(loaddata,features):\n",
    "    # Features are selected based on CFS\n",
    "    software_metrics = np.array(loaddata[features])\n",
    "    labels = np.array(loaddata['Defective'])\n",
    "    return software_metrics,labels\n",
    "\n",
    "def train_data(software_metrics,labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(software_metrics, labels, test_size = 0.1)\n",
    "    y_train = y_train.astype('str')\n",
    "    y_test = y_test.astype('str')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def feature_selection(fs,X):\n",
    "    dfscores = pd.DataFrame(fs.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    feature_scores = pd.concat([dfcolumns,dfscores.fillna(0)],axis=1)\n",
    "    feature_scores.columns = ['Feature','Score']\n",
    "    best_ten_features = feature_scores.nlargest(10,'Score')\n",
    "    return best_ten_features\n",
    "\n",
    "# def feature_selection_algo(X,Y):\n",
    "#     array = []\n",
    "#     data = [X,Y]\n",
    "#     cfs = cfs_algo(data)\n",
    "#     ridge = ridge_algo(data)\n",
    "#     print(f'Ridge score: {ridge.get_support()}')\n",
    "    # rfe = rfe_algo(data)\n",
    "    # print(f'RFE score: {rfe.score}')\n",
    "\n",
    "def main(filename):\n",
    "    # Read the file\n",
    "    loaddata = read_data('datasets/'+filename)\n",
    "\n",
    "    software_metrics = loaddata.iloc[:,:-1] #Software metrics\n",
    "    labels = loaddata.iloc[:,-1] #Labels\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_data(software_metrics,labels)\n",
    "\n",
    "    # ===== Feature Selection ====== #\n",
    "\n",
    "    # ==== CFS ==== #\n",
    "    data = [X_train,y_train]\n",
    "    cfs = cfs_algo(data)\n",
    "    cfs_best_ten_features = feature_selection(cfs,software_metrics)\n",
    "    print(cfs_best_ten_features)\n",
    "    # ============= #\n",
    "\n",
    "    # ===== Ridge ===== #\n",
    "    software_metrics = np.array(loaddata.iloc[:,:-1]) #Software metrics\n",
    "    labels = data_conversion(np.array(loaddata.iloc[:,-1])) #label \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_data(software_metrics,labels)\n",
    "\n",
    "    data = [X_train,y_train]\n",
    "    ridge = ridge_algo(data)\n",
    "    # print(ridge.intercept_)\n",
    "    # print(ridge.score(software_metrics,labels))\n",
    "    # features = best_ten_features['Feature'].values\n",
    "    # ===================== #\n",
    "\n",
    "    # ===== RFE ======== #\n",
    "    rfe = rfe_algo(data)\n",
    "    print(rfe.ranking_)\n",
    "\n",
    "    # software_metrics,labels = process_data(loaddata,features)\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_data(software_metrics,labels)\n",
    "\n",
    "    # Preprocessing\n",
    "    preprocessed_data = preprocess(filename)\n",
    "\n",
    "    # Algorithms\n",
    "    # return preprocessed_data\n",
    "\n",
    "filename = 'KC4.arff.txt'\n",
    "main(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea9cb6ab4d914a35d8e6d0a69a1d89f0d94b47e6dbf4bfc8b7ae98e3408380a4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
