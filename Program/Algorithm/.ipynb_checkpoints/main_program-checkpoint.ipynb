{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from tkinter import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('interface')\n",
    "\n",
    "# Allows jupyter notebook to be imported\n",
    "import jupyter_import\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tkPDFViewer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2df5a1dfd6e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0minterface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\interface\\main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# sys.path.append('interface')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlogin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhome\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAbout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\interface\\login.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmessagebox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#from home_train import HomeTrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#from home_pred import HomePred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\interface\\main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhome\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAbout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mttk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#from PIL import ImageTK, Image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\interface\\report.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmessagebox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mreport_pdf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#from home_train import HomeTrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#from home_pred import HomePred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\interface\\report_pdf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtkPDFViewer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtkPDFViewer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#from home_train import HomeTrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#from home_pred import HomePred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tkPDFViewer'"
     ]
    }
   ],
   "source": [
    "from interface.main import Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "# sys.path.append('interface')\n",
    "\n",
    "# Allows jupyter notebook to be imported\n",
    "import jupyter_import\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interface import *\n",
    "from interface.home import Home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preproc.Preprocess import preprocess, Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preproc.CFS import cfs_algo\n",
    "from data_preproc.RFE import rfe_algo\n",
    "from data_preproc.RR import ridge_algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pred_mdls.base.Complement_Naive_Bayes import complement_naive_bayes_model\n",
    "from pred_mdls.base.Decision_Tree import decision_tree_model\n",
    "from pred_mdls.base.Logistic_Regression import logistic_regression_model\n",
    "from pred_mdls.base.Multi_Layer_Perceptron import multi_layer_perceptron_model\n",
    "from pred_mdls.base.Naive_Bayes import naive_bayes_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pred_mdls.ensemble.Random_Forest import random_forest_model\n",
    "from pred_mdls.ensemble.Rotation_Forest import rotation_forest_model\n",
    "from pred_mdls.ensemble.Voting import voting_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pf_eval.AUC_ROC import auc_roc_model\n",
    "from pf_eval.F1_Score import f1_model\n",
    "from pf_eval.CSV import write_results\n",
    "from pf_eval.Confusion_Matrix import confusion_matrix_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_conversion(data):\n",
    "    for i in range(len(data)):\n",
    "        if data[i] == b'N' or data[i] == b'false' or data[i] == b'no':\n",
    "            data[i] = 0\n",
    "        else:\n",
    "            data[i] = 1\n",
    "    return data\n",
    "\n",
    "def read_data(filename):\n",
    "    data = arff.loadarff(filename)\n",
    "    loaddata = pd.DataFrame(data[0])\n",
    "    return loaddata\n",
    "\n",
    "def process_data(loaddata,features):\n",
    "    # Features are selected based on CFS\n",
    "    software_metrics = np.array(loaddata[features])\n",
    "    labels = np.array(loaddata['Defective'])\n",
    "    return software_metrics,labels\n",
    "\n",
    "def train_data(software_metrics,labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(software_metrics, labels, test_size = 0.1)\n",
    "    y_train = y_train.astype('str')\n",
    "    y_test = y_test.astype('str')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_data(model,model_name,X_test,y_test):\n",
    "    auc_score = auc_roc_model(model,X_test,y_test)\n",
    "    f1_score = f1_model(model,X_test,y_test)\n",
    "    fpr,fnr = confusion_matrix_model(model,X_test,y_test)\n",
    "    return auc_score,f1_score,fpr,fnr\n",
    "\n",
    "def translate(result):\n",
    "    count = 1\n",
    "    res = []\n",
    "    while count <= 3:\n",
    "        for i in range(len(result[0])):\n",
    "            res.append([result[0][i], result[1][((i+1)*count)-1],result[2][((i+1)*count)-1]])\n",
    "        count += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_writer(header,result):\n",
    "    #Writes the output of a single dataset for main function\n",
    "    filters = ['No filter','CFS','RFE']\n",
    "    with open('pred_results.csv','w',encoding='UTF8', newline='') as file:\n",
    "        res = csv.writer(file)\n",
    "        for i in range(len(filters)):\n",
    "            res.writerow('')\n",
    "            res.writerow([filters[i]])\n",
    "            res.writerow(header)\n",
    "            res.writerow([result[0][0]] + result[0][1][i*8:i*8+8])\n",
    "            res.writerow([result[1][0]] + result[1][1][i*8:i*8+8])\n",
    "    \n",
    "def run(datasets, savename, repository):\n",
    "    #Writes the output of multiple datasets for the main function\n",
    "    header = ['Model name','Complement Naive Bayes','Decision Tree','Logistic regression',\n",
    "                        'Multi Layer Perceptron','Naive Bayes','Random Forest','Rotation Forest','Voting']\n",
    "    filters = ['(All)','(CFS)','(RFE)']\n",
    "    with open(savename,'w',encoding='UTF8', newline='') as file:\n",
    "        results = []\n",
    "        for ds in datasets:\n",
    "            if repository == 'NASA':\n",
    "                results.append(main('datasets/NASA/' + ds + '.txt')[0])\n",
    "            else:\n",
    "                results.append(main('datasets/PROMISE/' + ds + '.txt')[0])\n",
    "        res = csv.writer(file)\n",
    "        for k in range(len(results[0])):\n",
    "            res.writerow([results[0][k][0]])\n",
    "            res.writerow(header)\n",
    "            for j in range(len(results)):\n",
    "                for i in range(len(filters)):\n",
    "                    res.writerow([datasets[j]+filters[i]] + results[j][k][1][i*8:i*8+8])\n",
    "            if k != len(results[0])-1:\n",
    "                res.writerow('')\n",
    "        #res.writerow([results[0][0][0]])\n",
    "        #res.writerow(header)        \n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][0][1][i*8:i*8+8])\n",
    "        #res.writerow('')\n",
    "        #res.writerow([results[0][1][0]])\n",
    "        #res.writerow(header)\n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][1][1][i*8:i*8+8])\n",
    "        #res.writerow('')\n",
    "        #res.writerow([results[0][2][0]])\n",
    "        #res.writerow(header)\n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][2][1][i*8:i*8+8])\n",
    "        #res.writerow('')\n",
    "        #res.writerow([results[0][3][0]])\n",
    "        #res.writerow(header)\n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][3][1][i*8:i*8+8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_run(filename):\n",
    "    # Read the file\n",
    "    loaddata = read_data(filename)\n",
    "    loaddata = Normalize(loaddata)\n",
    "    SM = np.array(loaddata.iloc[:,:-1]) #Software metrics\n",
    "    L = data_conversion(np.array(loaddata.iloc[:,-1])).astype(int) #Labels\n",
    "    data = [SM,L]\n",
    "    model_name = ['Complement Naive Bayes','Decision Tree','Logistic regression',\n",
    "                    'Multi Layer Perceptron','Naive Bayes','Random Forest','Rotation Forest','Voting'] #Models used\n",
    "    selection = \"\"\n",
    "    while selection.strip().replace(\" \",\"\").isdigit() == False:\n",
    "        selection = input(\"Please select which models you would like to use by inputting the numbers specified beside them.\\n\" \n",
    "        \"To make multiple selections, seperate the numbers by spaces.\\n\" \n",
    "        \"1. Complement Naive Bayes\\n\"  \n",
    "        \"2. Decision Tree\\n\" \n",
    "        \"3. Logistic regression\\n\" \n",
    "        \"4. Multi Layer Perceptron\\n\"  \n",
    "        \"5. Naive Bayes\\n\"  \n",
    "        \"6. Random Forest\\n\"  \n",
    "        \"7. Rotation Forest\\n\" \n",
    "        \"8. Voting\\n\")\n",
    "    selection = selection.strip().replace(\" \",\"\")\n",
    "    selection = sorted(selection)\n",
    "    selected_models = []\n",
    "    for i in selection:\n",
    "        selected_models.append((model_name[int(i-1)],model_name.index(model_name[int(i-1)]))\n",
    "    # ===== Feature Selection ====== #\n",
    "\n",
    "    # ==== CFS ==== #\n",
    "    cfs, cfs_selections = cfs_algo(data,10)\n",
    "    # ============= #\n",
    "\n",
    "    # ===== RFE ======== #\n",
    "    rfe, rfe_selections = rfe_algo(data,10)\n",
    "    # ================== #\n",
    "    \n",
    "    # ========= Preprocessing ============= #\n",
    "    pp = preprocess(loaddata)\n",
    "    pp_cfs = preprocess(loaddata, cfs_selections)\n",
    "    pp_rfe = preprocess(loaddata, rfe_selections)\n",
    "\n",
    "    pp_arr = [pp,pp_cfs,pp_rfe]\n",
    "    pp_name = ['No filters','CFS Feature Selection','RFE Feature Selection']\n",
    "    # ====================================== #\n",
    "\n",
    "    result = []\n",
    "    arr_size = len(selected_models)*len(pp_name) #Result array size\n",
    "    auc_arr = [0]*arr_size\n",
    "    f1_arr = [0]*arr_size\n",
    "    fpr_arr = [0]*arr_size\n",
    "    fnr_arr = [0]*arr_size\n",
    "    header = []\n",
    "    folds = 5\n",
    "    for j,pp in enumerate(pp_arr):\n",
    "        for i in range(folds):\n",
    "            data = [pp[i][0],pp[i][2]]\n",
    "            \n",
    "            # ======== Model Creation =========== #\n",
    "            # Base Predictors\n",
    "            cnb = complement_naive_bayes_model(data)\n",
    "            dt = decision_tree_model(data)\n",
    "            lr = logistic_regression_model(data)\n",
    "            mlp = multi_layer_perceptron_model(data)\n",
    "            nb = naive_bayes_model(data)\n",
    "\n",
    "            args = [1000]\n",
    "            # Ensemble Predictors\n",
    "            rf = random_forest_model(data,args)\n",
    "            rof = rotation_forest_model(data,args)\n",
    "            vt = voting_model(data,args)\n",
    "            # ==================================== #\n",
    "            models = [cnb,dt,lr,mlp,nb,rf,rof,vt]\n",
    "            used_models = []\n",
    "            for i in selection:\n",
    "                used_models.append(models[int(i-1)])\n",
    "            for k in range(len(used_models)):\n",
    "                auc_score,f1_score,fpr,fnr = evaluate_data(models[k],model_name[k],pp[i][1],pp[i][3])\n",
    "                if math.isnan(auc_score):\n",
    "                    #print(model_name[k], auc_score)\n",
    "                    auc_score = 0\n",
    "                auc_arr[(j*8)+k] += auc_score\n",
    "                f1_arr[(j*8)+k] += f1_score\n",
    "                fpr_arr[(j*8)+k] += fpr\n",
    "                fnr_arr[(j*8)+k] += fnr\n",
    "    for i in range(len(models)*3):\n",
    "        auc_arr[i] /= folds\n",
    "        auc_arr[i] = round(auc_arr[i],3)\n",
    "        f1_arr[i] /= folds\n",
    "        f1_arr[i] = round(f1_arr[i],3)\n",
    "        fpr_arr[i] /= folds\n",
    "        fpr_arr[i] = round(fpr_arr[i],3)\n",
    "        fnr_arr[i] /= folds\n",
    "        fnr_arr[i] = round(fnr_arr[i],3)\n",
    "    header.append('Model Name')\n",
    "    for i in selected_models:\n",
    "        header.append(i[0]) \n",
    "    result.append(('AUC', auc_arr))\n",
    "    result.append(('F1 Score', f1_arr))\n",
    "    result.append(('False Positive Rate', fpr_arr))\n",
    "    result.append(('False Negative Rate', fnr_arr))\n",
    "    #Print filename upon completion\n",
    "    print(filename)\n",
    "    return result, header     \n",
    "            \n",
    "if __name__=='__main__':\n",
    "    # N_filenames = ['CM1.arff','JM1.arff','KC1.arff','KC3.arff',\n",
    "    #                'KC4.arff','MC1.arff','MC2.arff','MW1.arff',\n",
    "    #                'PC1.arff','PC2.arff','PC3.arff','PC4.arff','PC5.arff']\n",
    "    # P_filenames = ['cm1.arff','jm1.arff','kc1.arff','kc2.arff','pc1.arff']\n",
    "    # run(N_filenames,'NASA.csv','NASA')\n",
    "    # run(P_filenames,'PROMISE.csv','PROMISE')\n",
    "    result, header = main_run('CM1.arff')\n",
    "    main_writer(header,result)                           \n",
    "    #root = Tk()\n",
    "    #main_root = Main(root)\n",
    "    #print(main_root.get_results())\n",
    "    #root.title('Prediction software')\n",
    "    #root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tkPDFViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
