{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import csv\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.io import arff\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "import math\r\n",
    "\r\n",
    "# sys.path.append('interface')\r\n",
    "\r\n",
    "# Allows jupyter notebook to be imported\r\n",
    "import jupyter_import\r\n",
    "\r\n",
    "# Suppress Warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# User Interface"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from interface import *\r\n",
    "from interface.home import Home"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from data_preproc.Preprocess import preprocess, Normalize"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\data_preproc\\Preprocess.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from data_preproc.CFS import cfs_algo\r\n",
    "from data_preproc.RFE import rfe_algo\r\n",
    "from data_preproc.RR import ridge_algo"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\data_preproc\\CFS.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\data_preproc\\RFE.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\data_preproc\\RR.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base Predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from pred_mdls.base.Complement_Naive_Bayes import complement_naive_bayes_model\n",
    "from pred_mdls.base.Decision_Tree import decision_tree_model\n",
    "from pred_mdls.base.Logistic_Regression import logistic_regression_model\n",
    "from pred_mdls.base.Multi_Layer_Perceptron import multi_layer_perceptron_model\n",
    "from pred_mdls.base.Naive_Bayes import naive_bayes_model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\base\\Complement_Naive_Bayes.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\base\\Decision_Tree.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\base\\Logistic_Regression.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\base\\Multi_Layer_Perceptron.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\base\\Naive_Bayes.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble Predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from pred_mdls.ensemble.Random_Forest import random_forest_model\n",
    "from pred_mdls.ensemble.Rotation_Forest import rotation_forest_model\n",
    "from pred_mdls.ensemble.Voting import voting_model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\ensemble\\Random_Forest.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\ensemble\\Rotation_Forest.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pred_mdls\\ensemble\\Voting.ipynb\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from pf_eval.AUC_ROC import auc_roc_model\n",
    "from pf_eval.F1_Score import f1_model\n",
    "from pf_eval.CSV import write_results\n",
    "from pf_eval.Confusion_Matrix import confusion_matrix_model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pf_eval\\AUC_ROC.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pf_eval\\F1_Score.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pf_eval\\CSV.ipynb\n",
      "importing Jupyter notebook from D:\\FYP i guess\\I need to do Naive Bayes\\Program\\Algorithm\\pf_eval\\Confusion_Matrix.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Additional Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def data_conversion(data):\n",
    "    for i in range(len(data)):\n",
    "        if data[i] == b'N' or data[i] == b'false' or data[i] == b'no':\n",
    "            data[i] = 0\n",
    "        else:\n",
    "            data[i] = 1\n",
    "    return data\n",
    "\n",
    "def read_data(filename):\n",
    "    data = arff.loadarff(filename)\n",
    "    loaddata = pd.DataFrame(data[0])\n",
    "    return loaddata\n",
    "\n",
    "def process_data(loaddata,features):\n",
    "    # Features are selected based on CFS\n",
    "    software_metrics = np.array(loaddata[features])\n",
    "    labels = np.array(loaddata['Defective'])\n",
    "    return software_metrics,labels\n",
    "\n",
    "def train_data(software_metrics,labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(software_metrics, labels, test_size = 0.1)\n",
    "    y_train = y_train.astype('str')\n",
    "    y_test = y_test.astype('str')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_data(model,model_name,X_test,y_test):\n",
    "    auc_score = auc_roc_model(model,X_test,y_test)\n",
    "    f1_score = f1_model(model,X_test,y_test)\n",
    "    fpr,fnr = confusion_matrix_model(model,X_test,y_test)\n",
    "    return auc_score,f1_score,fpr,fnr\n",
    "\n",
    "def translate(result):\n",
    "    count = 1\n",
    "    res = []\n",
    "    while count <= 3:\n",
    "        for i in range(len(result[0])):\n",
    "            res.append([result[0][i], result[1][((i+1)*count)-1],result[2][((i+1)*count)-1]])\n",
    "        count += 1\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result writers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def main_writer(header,result):\n",
    "    #Writes the output of a single dataset for main function\n",
    "    filters = ['No filter','CFS','RFE']\n",
    "    with open('pred_results.csv','w',encoding='UTF8', newline='') as file:\n",
    "        res = csv.writer(file)\n",
    "        for i in range(len(filters)):\n",
    "            res.writerow('')\n",
    "            res.writerow([filters[i]])\n",
    "            res.writerow(header)\n",
    "            res.writerow([result[0][0]] + result[0][1][i*8:i*8+8])\n",
    "            res.writerow([result[1][0]] + result[1][1][i*8:i*8+8])\n",
    "    \n",
    "def run(datasets, savename, repository):\n",
    "    #Writes the output of multiple datasets for the main function\n",
    "    header = ['Model name','Complement Naive Bayes','Decision Tree','Logistic regression',\n",
    "                        'Multi Layer Perceptron','Naive Bayes','Random Forest','Rotation Forest','Voting']\n",
    "    filters = ['(All)','(CFS)','(RFE)']\n",
    "    with open(savename,'w',encoding='UTF8', newline='') as file:\n",
    "        results = []\n",
    "        for ds in datasets:\n",
    "            if repository == 'NASA':\n",
    "                results.append(main('datasets/NASA/' + ds + '.txt')[0])\n",
    "            else:\n",
    "                results.append(main('datasets/PROMISE/' + ds + '.txt')[0])\n",
    "        res = csv.writer(file)\n",
    "        for k in range(len(results[0])):\n",
    "            res.writerow([results[0][k][0]])\n",
    "            res.writerow(header)\n",
    "            for j in range(len(results)):\n",
    "                for i in range(len(filters)):\n",
    "                    res.writerow([datasets[j]+filters[i]] + results[j][k][1][i*8:i*8+8])\n",
    "            if k != len(results[0])-1:\n",
    "                res.writerow('')\n",
    "        #res.writerow([results[0][0][0]])\n",
    "        #res.writerow(header)        \n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][0][1][i*8:i*8+8])\n",
    "        #res.writerow('')\n",
    "        #res.writerow([results[0][1][0]])\n",
    "        #res.writerow(header)\n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][1][1][i*8:i*8+8])\n",
    "        #res.writerow('')\n",
    "        #res.writerow([results[0][2][0]])\n",
    "        #res.writerow(header)\n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][2][1][i*8:i*8+8])\n",
    "        #res.writerow('')\n",
    "        #res.writerow([results[0][3][0]])\n",
    "        #res.writerow(header)\n",
    "        #for j in range(len(results)):\n",
    "            #for i in range(len(filters)):\n",
    "                #res.writerow([datasets[j]+filters[i]] + results[j][3][1][i*8:i*8+8])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def main_run(filename):\n",
    "    # Read the file\n",
    "    loaddata = read_data(filename)\n",
    "    loaddata = Normalize(loaddata)\n",
    "    SM = np.array(loaddata.iloc[:,:-1]) #Software metrics\n",
    "    L = data_conversion(np.array(loaddata.iloc[:,-1])).astype(int) #Labels\n",
    "    data = [SM,L]\n",
    "    model_name = ['Complement Naive Bayes','Decision Tree','Logistic regression',\n",
    "                    'Multi Layer Perceptron','Naive Bayes','Random Forest','Rotation Forest','Voting'] #Models used\n",
    "    selection = \"\"\n",
    "    while selection.strip().replace(\" \",\"\").isdigit() == False:\n",
    "        selection = input(\"Please select which models you would like to use by inputting the numbers specified beside them.\\n\" \n",
    "        \"To make multiple selections, seperate the numbers by spaces.\\n\" \n",
    "        \"1. Complement Naive Bayes\\n\"  \n",
    "        \"2. Decision Tree\\n\" \n",
    "        \"3. Logistic regression\\n\" \n",
    "        \"4. Multi Layer Perceptron\\n\"  \n",
    "        \"5. Naive Bayes\\n\"  \n",
    "        \"6. Random Forest\\n\"  \n",
    "        \"7. Rotation Forest\\n\" \n",
    "        \"8. Voting\\n\")\n",
    "    selection = selection.strip().replace(\" \",\"\")\n",
    "    selection = sorted(selection)\n",
    "    selected_models = []\n",
    "    for i in selection:\n",
    "        selected_models.append((model_name[int(i)-1],model_name.index(model_name[int(i)-1])))\n",
    "    print(selected_models)\n",
    "    # ===== Feature Selection ====== #\n",
    "\n",
    "    # ==== CFS ==== #\n",
    "    cfs, cfs_selections = cfs_algo(data,10)\n",
    "    # ============= #\n",
    "\n",
    "    # ===== RFE ======== #\n",
    "    rfe, rfe_selections = rfe_algo(data,10)\n",
    "    # ================== #\n",
    "    \n",
    "    # ========= Preprocessing ============= #\n",
    "    pp = preprocess(loaddata)\n",
    "    pp_cfs = preprocess(loaddata, cfs_selections)\n",
    "    pp_rfe = preprocess(loaddata, rfe_selections)\n",
    "\n",
    "    pp_arr = [pp,pp_cfs,pp_rfe]\n",
    "    pp_name = ['No filters','CFS Feature Selection','RFE Feature Selection']\n",
    "    # ====================================== #\n",
    "\n",
    "    result = []\n",
    "    arr_size = len(selected_models)*len(pp_name) #Result array size\n",
    "    auc_arr = [0]*arr_size\n",
    "    f1_arr = [0]*arr_size\n",
    "    fpr_arr = [0]*arr_size\n",
    "    fnr_arr = [0]*arr_size\n",
    "    header = []\n",
    "    folds = 5\n",
    "    for j,pp in enumerate(pp_arr):\n",
    "        for i in range(folds):\n",
    "            data = [pp[i][0],pp[i][2]]\n",
    "            \n",
    "            # ======== Model Creation =========== #\n",
    "            # Base Predictors\n",
    "            cnb = complement_naive_bayes_model(data)\n",
    "            dt = decision_tree_model(data)\n",
    "            lr = logistic_regression_model(data)\n",
    "            mlp = multi_layer_perceptron_model(data)\n",
    "            nb = naive_bayes_model(data)\n",
    "\n",
    "            args = [1000]\n",
    "            # Ensemble Predictors\n",
    "            rf = random_forest_model(data,args)\n",
    "            rof = rotation_forest_model(data,args)\n",
    "            vt = voting_model(data,args)\n",
    "            # ==================================== #\n",
    "            models = [cnb,dt,lr,mlp,nb,rf,rof,vt]\n",
    "            used_models = []\n",
    "            for x in selection:\n",
    "                used_models.append(models[int(x)-1])\n",
    "            for k in range(len(used_models)):\n",
    "                auc_score,f1_score,fpr,fnr = evaluate_data(used_models[k],selected_models[k],pp[i][1],pp[i][3])\n",
    "                if math.isnan(auc_score):\n",
    "                    #print(model_name[k], auc_score)\n",
    "                    auc_score = 0\n",
    "                auc_arr[(j*len(selected_models))+k] += auc_score\n",
    "                f1_arr[(j*len(selected_models))+k] += f1_score\n",
    "                fpr_arr[(j*len(selected_models))+k] += fpr\n",
    "                fnr_arr[(j*len(selected_models))+k] += fnr\n",
    "    for i in range(len(used_models)*3):\n",
    "        auc_arr[i] /= folds\n",
    "        auc_arr[i] = round(auc_arr[i],3)\n",
    "        f1_arr[i] /= folds\n",
    "        f1_arr[i] = round(f1_arr[i],3)\n",
    "        fpr_arr[i] /= folds\n",
    "        fpr_arr[i] = round(fpr_arr[i],3)\n",
    "        fnr_arr[i] /= folds\n",
    "        fnr_arr[i] = round(fnr_arr[i],3)\n",
    "    header.append('Model Name')\n",
    "    for i in selected_models:\n",
    "        header.append(i[0]) \n",
    "    result.append(('AUC', auc_arr))\n",
    "    result.append(('F1 Score', f1_arr))\n",
    "    result.append(('False Positive Rate', fpr_arr))\n",
    "    result.append(('False Negative Rate', fnr_arr))\n",
    "    #Print filename upon completion\n",
    "    print(filename)\n",
    "    return result, header     \n",
    "            \n",
    "if __name__=='__main__':\n",
    "    # N_filenames = ['CM1.arff','JM1.arff','KC1.arff','KC3.arff',\n",
    "    #                'KC4.arff','MC1.arff','MC2.arff','MW1.arff',\n",
    "    #                'PC1.arff','PC2.arff','PC3.arff','PC4.arff','PC5.arff']\n",
    "    # P_filenames = ['cm1.arff','jm1.arff','kc1.arff','kc2.arff','pc1.arff']\n",
    "    # run(N_filenames,'NASA.csv','NASA')\n",
    "    # run(P_filenames,'PROMISE.csv','PROMISE')\n",
    "    #========== Running main program =========#\n",
    "    #result, header = main_run('datasets/NASA/CM1.arff.txt')\n",
    "    #main_writer(header,result)\n",
    "    \n",
    "    #========== Running interface =========#\n",
    "    root = Tk()\n",
    "    main_root = Main(root)\n",
    "    print(main_root.get_results())\n",
    "    root.title('Prediction software')\n",
    "    #root.mainloop()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Please select which models you would like to use by inputting the numbers specified beside them.\n",
      "To make multiple selections, seperate the numbers by spaces.\n",
      "1. Complement Naive Bayes\n",
      "2. Decision Tree\n",
      "3. Logistic regression\n",
      "4. Multi Layer Perceptron\n",
      "5. Naive Bayes\n",
      "6. Random Forest\n",
      "7. Rotation Forest\n",
      "8. Voting\n",
      "1 3 2\n",
      "[('Complement Naive Bayes', 0), ('Decision Tree', 1), ('Logistic regression', 2)]\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "datasets/NASA/CM1.arff.txt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}