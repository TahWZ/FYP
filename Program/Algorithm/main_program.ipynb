{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.io import arff\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "# Suppress Warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#========== IMPORTS =============#\r\n",
    "# Allows jupyter notebook to be imported\r\n",
    "import jupyter_import\r\n",
    "from data_preproc.Preprocess import preprocess, Normalize\r\n",
    "#================================#"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from data_preproc.CFS import cfs_algo\r\n",
    "from data_preproc.RFE import rfe_algo\r\n",
    "from data_preproc.RR import ridge_algo"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base Predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from pred_mdls.base.Complement_Naive_Bayes import complement_naive_bayes_model\r\n",
    "from pred_mdls.base.Decision_Tree import decision_tree_model\r\n",
    "from pred_mdls.base.Logistic_Regression import logistic_regression_model\r\n",
    "from pred_mdls.base.Multi_Layer_Perceptron import multi_layer_perceptron_model\r\n",
    "from pred_mdls.base.Naive_Bayes import naive_bayes_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble Predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from pred_mdls.ensemble.Random_Forest import random_forest_model\r\n",
    "from pred_mdls.ensemble.Rotation_Forest import rotation_forest_model\r\n",
    "from pred_mdls.ensemble.Voting import voting_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from pf_eval.AUC_ROC import auc_roc_model\r\n",
    "from pf_eval.F1_Score import f1_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def data_conversion(data):\r\n",
    "    for i in range(len(data)):\r\n",
    "        if data[i] == b'N':\r\n",
    "            data[i] = 0\r\n",
    "        else:\r\n",
    "            data[i] = 1\r\n",
    "    return data\r\n",
    "\r\n",
    "def read_data(filename):\r\n",
    "    data = arff.loadarff(filename)\r\n",
    "    loaddata = pd.DataFrame(data[0])\r\n",
    "    return loaddata\r\n",
    "\r\n",
    "def process_data(loaddata,features):\r\n",
    "    # Features are selected based on CFS\r\n",
    "    software_metrics = np.array(loaddata[features])\r\n",
    "    labels = np.array(loaddata['Defective'])\r\n",
    "    return software_metrics,labels\r\n",
    "\r\n",
    "def train_data(software_metrics,labels):\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(software_metrics, labels, test_size = 0.1)\r\n",
    "    y_train = y_train.astype('str')\r\n",
    "    y_test = y_test.astype('str')\r\n",
    "    return X_train, X_test, y_train, y_test\r\n",
    "\r\n",
    "def evaluate_data(model,model_name,X_test,y_test):\r\n",
    "    predictions = model.predict(X_test)\r\n",
    "    auc_score = round(auc_roc_model(model,X_test,y_test),2)\r\n",
    "    f1_score = round(f1_model(model,X_test,y_test),2)\r\n",
    "    print(f\"Model Name: {model_name}\")\r\n",
    "    print(f'Accuracy: {round(metrics.accuracy_score(y_test, predictions)*100,2)}%')\r\n",
    "    print(f'AUC Score: {auc_score}')\r\n",
    "    print(f'F1-score: {f1_score}')\r\n",
    "    return auc_score,f1_score\r\n",
    "\r\n",
    "def main(filename):\r\n",
    "    # Read the file\r\n",
    "    loaddata = read_data(filename)\r\n",
    "    loaddata = Normalize(loaddata)\r\n",
    "    #software_metrics = loaddata.iloc[:,:-1] #Software metrics\r\n",
    "    #labels = loaddata.iloc[:,-1] #Labels\r\n",
    "    SM = np.array(loaddata.iloc[:,:-1]) #Software metrics\r\n",
    "    L = data_conversion(np.array(loaddata.iloc[:,-1])).astype(int) #Labels\r\n",
    "    data = [SM,L]\r\n",
    "       \r\n",
    "    # ===== Feature Selection ====== #\r\n",
    "\r\n",
    "    # ==== CFS ==== #\r\n",
    "    cfs, cfs_selections = cfs_algo(data,10)\r\n",
    "    # ============= #\r\n",
    "\r\n",
    "    # ===== RFE ======== #\r\n",
    "    rfe, rfe_selections = rfe_algo(data,10)\r\n",
    "    # ================== #\r\n",
    "    \r\n",
    "    # ========= Preprocessing ============= #\r\n",
    "    pp = preprocess(loaddata)\r\n",
    "    pp_cfs = preprocess(loaddata, cfs_selections)\r\n",
    "    pp_rfe = preprocess(loaddata, rfe_selections)\r\n",
    "\r\n",
    "    pp_arr = [pp,pp_cfs,pp_rfe]\r\n",
    "    pp_name = ['No filters','CFS Feature Selection','RFE Feature Selection']\r\n",
    "    args = [1000]\r\n",
    "    # ====================================== #\r\n",
    "\r\n",
    "    result = []\r\n",
    "    auc_arr = []\r\n",
    "    f1_arr = []\r\n",
    "\r\n",
    "    for i,pp in enumerate(pp_arr):\r\n",
    "        print(pp_name[i])\r\n",
    "        data = [pp[0][0],pp[0][2]]\r\n",
    "    \r\n",
    "        # ======== Model Creation =========== #\r\n",
    "        # Base Predictors\r\n",
    "        cnb = complement_naive_bayes_model(data,args)\r\n",
    "        dt = decision_tree_model(data,args)\r\n",
    "        lr = logistic_regression_model(data,args)\r\n",
    "        mlp = multi_layer_perceptron_model(data,args)\r\n",
    "        nb = naive_bayes_model(data,args)\r\n",
    "\r\n",
    "        # Ensemble Predictors\r\n",
    "        rf = random_forest_model(data,args)\r\n",
    "        rof = rotation_forest_model(data,args)\r\n",
    "        vt = voting_model(data,args)\r\n",
    "        # ==================================== #\r\n",
    "\r\n",
    "        models = [cnb,dt,lr,mlp,nb,rf,rof,vt] \r\n",
    "        model_name = ['Complement Naive Bayes','Decision Tree','Logistic regression',\r\n",
    "                        'Multi Layer Perceptron','Naive Bayes','Random Forest','Rotation Forest','Voting']\r\n",
    "        for i in range(len(models)):\r\n",
    "            print('*'*50)\r\n",
    "            auc_score,f1_score = evaluate_data(models[i],model_name[i],pp[0][1],pp[0][3])\r\n",
    "            auc_arr.append(auc_score)\r\n",
    "            f1_arr.append(f1_score)\r\n",
    "        print('='*100)\r\n",
    "    result.append('Model Name')\r\n",
    "    result.append(model_name)\r\n",
    "    result.append('AUC')\r\n",
    "    result.append(auc_arr)\r\n",
    "    result.append('F1 Score')\r\n",
    "    result.append(f1_arr)\r\n",
    "    return result\r\n",
    "\r\n",
    "if __name__=='__main__':\r\n",
    "    filename = 'datasets/KC4.arff.txt'\r\n",
    "    result = main(filename)\r\n",
    "\r\n",
    "    for elem in result:\r\n",
    "        print(elem)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No filters\n",
      "**************************************************\n",
      "Model Name: Complement Naive Bayes\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 1.0\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Decision Tree\n",
      "Accuracy: 75.0%\n",
      "AUC Score: 0.75\n",
      "F1-score: 80.0\n",
      "**************************************************\n",
      "Model Name: Logistic regression\n",
      "Accuracy: 75.0%\n",
      "AUC Score: 1.0\n",
      "F1-score: 80.0\n",
      "**************************************************\n",
      "Model Name: Multi Layer Perceptron\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.88\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Naive Bayes\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.84\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Random Forest\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 1.0\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Rotation Forest\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.88\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Voting\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 1.0\n",
      "F1-score: 88.89\n",
      "====================================================================================================\n",
      "CFS Feature Selection\n",
      "**************************************************\n",
      "Model Name: Complement Naive Bayes\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 1.0\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Decision Tree\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.88\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Logistic regression\n",
      "Accuracy: 75.0%\n",
      "AUC Score: 1.0\n",
      "F1-score: 80.0\n",
      "**************************************************\n",
      "Model Name: Multi Layer Perceptron\n",
      "Accuracy: 75.0%\n",
      "AUC Score: 0.88\n",
      "F1-score: 80.0\n",
      "**************************************************\n",
      "Model Name: Naive Bayes\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.84\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Random Forest\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.94\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Rotation Forest\n",
      "Accuracy: 75.0%\n",
      "AUC Score: 0.88\n",
      "F1-score: 80.0\n",
      "**************************************************\n",
      "Model Name: Voting\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.94\n",
      "F1-score: 88.89\n",
      "====================================================================================================\n",
      "RFE Feature Selection\n",
      "**************************************************\n",
      "Model Name: Complement Naive Bayes\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 1.0\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Decision Tree\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.88\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Logistic regression\n",
      "Accuracy: 75.0%\n",
      "AUC Score: 1.0\n",
      "F1-score: 80.0\n",
      "**************************************************\n",
      "Model Name: Multi Layer Perceptron\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.88\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Naive Bayes\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.84\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Random Forest\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 1.0\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Rotation Forest\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 0.88\n",
      "F1-score: 88.89\n",
      "**************************************************\n",
      "Model Name: Voting\n",
      "Accuracy: 87.5%\n",
      "AUC Score: 1.0\n",
      "F1-score: 88.89\n",
      "====================================================================================================\n",
      "['Model Name']\n",
      "['Complement Naive Bayes', 'Decision Tree', 'Logistic regression', 'Multi Layer Perceptron', 'Naive Bayes', 'Random Forest', 'Rotation Forest', 'Voting']\n",
      "['AUC']\n",
      "[1.0, 0.75, 1.0, 0.88, 0.84, 1.0, 0.88, 1.0, 1.0, 0.88, 1.0, 0.88, 0.84, 0.94, 0.88, 0.94, 1.0, 0.88, 1.0, 0.88, 0.84, 1.0, 0.88, 1.0]\n",
      "['F1 Score']\n",
      "[88.89, 80.0, 80.0, 88.89, 88.89, 88.89, 88.89, 88.89, 88.89, 88.89, 80.0, 80.0, 88.89, 88.89, 80.0, 88.89, 88.89, 88.89, 80.0, 88.89, 88.89, 88.89, 88.89, 88.89]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea9cb6ab4d914a35d8e6d0a69a1d89f0d94b47e6dbf4bfc8b7ae98e3408380a4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}