{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import csv\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.io import arff\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "import math\r\n",
    "\r\n",
    "# Suppress Warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#========== IMPORTS =============#\r\n",
    "# Allows jupyter notebook to be imported\r\n",
    "import jupyter_import\r\n",
    "from data_preproc.Preprocess import preprocess, Normalize\r\n",
    "#================================#"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\data_preproc\\Preprocess.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from data_preproc.CFS import cfs_algo\r\n",
    "from data_preproc.RFE import rfe_algo\r\n",
    "from data_preproc.RR import ridge_algo"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\data_preproc\\CFS.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\data_preproc\\RFE.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\data_preproc\\RR.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base Predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from pred_mdls.base.Complement_Naive_Bayes import complement_naive_bayes_model\r\n",
    "from pred_mdls.base.Decision_Tree import decision_tree_model\r\n",
    "from pred_mdls.base.Logistic_Regression import logistic_regression_model\r\n",
    "from pred_mdls.base.Multi_Layer_Perceptron import multi_layer_perceptron_model\r\n",
    "from pred_mdls.base.Naive_Bayes import naive_bayes_model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\base\\Complement_Naive_Bayes.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\base\\Decision_Tree.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\base\\Logistic_Regression.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\base\\Multi_Layer_Perceptron.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\base\\Naive_Bayes.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble Predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from pred_mdls.ensemble.Random_Forest import random_forest_model\r\n",
    "from pred_mdls.ensemble.Rotation_Forest import rotation_forest_model\r\n",
    "from pred_mdls.ensemble.Voting import voting_model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\ensemble\\Random_Forest.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\ensemble\\Rotation_Forest.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pred_mdls\\ensemble\\Voting.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from pf_eval.AUC_ROC import auc_roc_model\r\n",
    "from pf_eval.F1_Score import f1_model\r\n",
    "from pf_eval.CSV import write_results"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pf_eval\\AUC_ROC.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pf_eval\\F1_Score.ipynb\n",
      "importing Jupyter notebook from c:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pf_eval\\CSV.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def data_conversion(data):\r\n",
    "    for i in range(len(data)):\r\n",
    "        if data[i] == b'N' or data[i] == b'false':\r\n",
    "            data[i] = 0\r\n",
    "        else:\r\n",
    "            data[i] = 1\r\n",
    "    return data\r\n",
    "\r\n",
    "def read_data(filename):\r\n",
    "    data = arff.loadarff(filename)\r\n",
    "    loaddata = pd.DataFrame(data[0])\r\n",
    "    return loaddata\r\n",
    "\r\n",
    "def process_data(loaddata,features):\r\n",
    "    # Features are selected based on CFS\r\n",
    "    software_metrics = np.array(loaddata[features])\r\n",
    "    labels = np.array(loaddata['Defective'])\r\n",
    "    return software_metrics,labels\r\n",
    "\r\n",
    "def train_data(software_metrics,labels):\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(software_metrics, labels, test_size = 0.1)\r\n",
    "    y_train = y_train.astype('str')\r\n",
    "    y_test = y_test.astype('str')\r\n",
    "    return X_train, X_test, y_train, y_test\r\n",
    "\r\n",
    "def evaluate_data(model,model_name,X_test,y_test):\r\n",
    "    predictions = model.predict(X_test)\r\n",
    "    auc_score = round(auc_roc_model(model,X_test,y_test),2)\r\n",
    "    f1_score = round(f1_model(model,X_test,y_test),2)\r\n",
    "    #print(f\"Model Name: {model_name}\")\r\n",
    "    #print(f'Accuracy: {round(metrics.accuracy_score(y_test, predictions)*100,2)}%')\r\n",
    "    #print(f'AUC Score: {auc_score}')\r\n",
    "    #print(f'F1-score: {f1_score}')\r\n",
    "    return auc_score,f1_score\r\n",
    "\r\n",
    "def translate(result):\r\n",
    "    count = 1\r\n",
    "    res = []\r\n",
    "    while count <= 3:\r\n",
    "        for i in range(len(result[0])):\r\n",
    "            res.append([result[0][i], result[1][((i+1)*count)-1],result[2][((i+1)*count)-1]])\r\n",
    "        count += 1\r\n",
    "    return res\r\n",
    "\r\n",
    "def write_results_S(header,result):\r\n",
    "    filters = ['No filter','CFS','RFE']\r\n",
    "    #header = ['Dataset', 'Algo 1', 'Algo 2','Algo 3']\r\n",
    "    #dummy = [['CM1','95%','92%','87%'], ['KC1','Trying','To','Test'],['KC4','90%','80%','70%']]\r\n",
    "    with open('pred_results.csv','w',encoding='UTF8', newline='') as file:\r\n",
    "        res = csv.writer(file)\r\n",
    "        for i in range(len(filters)):\r\n",
    "            res.writerow('')\r\n",
    "            res.writerow([filters[i]])\r\n",
    "            res.writerow(header)\r\n",
    "            res.writerow([result[0][0]] + result[0][1][i*8:i*8+8])\r\n",
    "            res.writerow([result[1][0]] + result[1][1][i*8:i*8+8])\r\n",
    "    \r\n",
    "def run(datasets, savename):\r\n",
    "    #result, header = main(filename)\r\n",
    "    #output = write_results_M(header,result)\r\n",
    "    header = ['Model name','Complement Naive Bayes','Decision Tree','Logistic regression',\r\n",
    "                        'Multi Layer Perceptron','Naive Bayes','Random Forest','Rotation Forest','Voting']\r\n",
    "    filters = ['(All)','(CFS)','(RFE)']\r\n",
    "    #header = ['Dataset', 'Algo 1', 'Algo 2','Algo 3']\r\n",
    "    #dummy = [['CM1','95%','92%','87%'], ['KC1','Trying','To','Test'],['KC4','90%','80%','70%']]\r\n",
    "    with open(savename,'w',encoding='UTF8', newline='') as file:\r\n",
    "        results = []\r\n",
    "        for ds in datasets:\r\n",
    "            results.append(main('datasets/NASA/' + ds + '.txt')[0])\r\n",
    "        res = csv.writer(file)\r\n",
    "        res.writerow([results[0][0][0]])\r\n",
    "        res.writerow(header)\r\n",
    "        for j in range(len(results)):\r\n",
    "            for i in range(len(filters)):\r\n",
    "                res.writerow([datasets[j]+filters[i]] + results[j][0][1][i*8:i*8+8])\r\n",
    "        res.writerow('')\r\n",
    "        res.writerow([results[0][1][0]])\r\n",
    "        res.writerow(header)\r\n",
    "        for j in range(len(results)):\r\n",
    "            for i in range(len(filters)):\r\n",
    "                res.writerow([datasets[j]+filters[i]] + results[j][1][1][i*8:i*8+8])\r\n",
    "    \r\n",
    "def main(filename):\r\n",
    "    print(filename)\r\n",
    "    # Read the file\r\n",
    "    loaddata = read_data(filename)\r\n",
    "    loaddata = Normalize(loaddata)\r\n",
    "    #software_metrics = loaddata.iloc[:,:-1] #Software metrics\r\n",
    "    #labels = loaddata.iloc[:,-1] #Labels\r\n",
    "    SM = np.array(loaddata.iloc[:,:-1]) #Software metrics\r\n",
    "    L = data_conversion(np.array(loaddata.iloc[:,-1])).astype(int) #Labels\r\n",
    "    data = [SM,L]\r\n",
    "    #print(data)\r\n",
    "    # ===== Feature Selection ====== #\r\n",
    "\r\n",
    "    # ==== CFS ==== #\r\n",
    "    cfs, cfs_selections = cfs_algo(data,10)\r\n",
    "    # ============= #\r\n",
    "\r\n",
    "    # ===== RFE ======== #\r\n",
    "    rfe, rfe_selections = rfe_algo(data,10)\r\n",
    "    # ================== #\r\n",
    "    \r\n",
    "    # ========= Preprocessing ============= #\r\n",
    "    pp = preprocess(loaddata)\r\n",
    "    pp_cfs = preprocess(loaddata, cfs_selections)\r\n",
    "    pp_rfe = preprocess(loaddata, rfe_selections)\r\n",
    "\r\n",
    "    pp_arr = [pp,pp_cfs,pp_rfe]\r\n",
    "    pp_name = ['No filters','CFS Feature Selection','RFE Feature Selection']\r\n",
    "    args = [1000]\r\n",
    "    # ====================================== #\r\n",
    "\r\n",
    "    result = []\r\n",
    "    auc_arr = [0]*24\r\n",
    "    f1_arr = [0]*24\r\n",
    "    header = []\r\n",
    "    folds = 5\r\n",
    "    for j,pp in enumerate(pp_arr):\r\n",
    "        #print(pp_name[i])\r\n",
    "        for i in range(folds):\r\n",
    "            data = [pp[i][0],pp[i][2]]\r\n",
    "\r\n",
    "            # ======== Model Creation =========== #\r\n",
    "            # Base Predictors\r\n",
    "            cnb = complement_naive_bayes_model(data,args)\r\n",
    "            dt = decision_tree_model(data,args)\r\n",
    "            lr = logistic_regression_model(data,args)\r\n",
    "            mlp = multi_layer_perceptron_model(data,args)\r\n",
    "            nb = naive_bayes_model(data,args)\r\n",
    "\r\n",
    "            # Ensemble Predictors\r\n",
    "            rf = random_forest_model(data,args)\r\n",
    "            rof = rotation_forest_model(data,args)\r\n",
    "            vt = voting_model(data,args)\r\n",
    "            # ==================================== #\r\n",
    "\r\n",
    "            models = [cnb,dt,lr,mlp,nb,rf,rof,vt] \r\n",
    "            model_name = ['Complement Naive Bayes','Decision Tree','Logistic regression',\r\n",
    "                            'Multi Layer Perceptron','Naive Bayes','Random Forest','Rotation Forest','Voting']\r\n",
    "            for k in range(len(models)):\r\n",
    "                #print('*'*50)\r\n",
    "                auc_score,f1_score = evaluate_data(models[k],model_name[k],pp[i][1],pp[i][3])\r\n",
    "                if math.isnan(auc_score):\r\n",
    "                    print(model_name[k], auc_score)\r\n",
    "                    auc_score = 0\r\n",
    "                # if math.isnan(f1_score):\r\n",
    "                #     f1_score = 0\r\n",
    "                auc_arr[(j*8)+k] += auc_score\r\n",
    "                f1_arr[(j*8)+k] += f1_score\r\n",
    "            #print('='*100)\r\n",
    "    for i in range(len(models)*3):\r\n",
    "        auc_arr[i] /= folds\r\n",
    "        f1_arr[i] /= folds\r\n",
    "    header.append('Model Name')\r\n",
    "    header += model_name\r\n",
    "    #result.append(model_name)\r\n",
    "    result.append(('AUC', auc_arr))\r\n",
    "    result.append(('F1 Score', f1_arr))\r\n",
    "    return result, header     \r\n",
    "            \r\n",
    "if __name__=='__main__':\r\n",
    "    #filename = 'datasets/NASA/KC4.arff.txt'\r\n",
    "    #'CM1.arff','JM1.arff','KC1.arff','KC4.arff','MC2.arff','PC1.arff'\r\n",
    "    N_filenames = ['MW1.arff','CM1.arff','JM1.arff','KC1.arff','KC4.arff','MC2.arff','PC1.arff','PC3.arff',\r\n",
    "               'PC4.arff','PC5.arff']\r\n",
    "    P_filenames = ['cm1.arff','jm1.arff','kc1.arff','kc2.arff','pc1.arff']\r\n",
    "\r\n",
    "\r\n",
    "    # AUC\r\n",
    "    # Take dataset not in the list (MW1.arff)\r\n",
    "\r\n",
    "    # F1\r\n",
    "    # CM1, JM1\r\n",
    "\r\n",
    "    #for i in range(len(N_filenames)):\r\n",
    "    #    N_filenames[i] = 'datasets/NASA/' + N_filenames[i] + '.txt'\r\n",
    "    #for i in range(len(P_filenames)):\r\n",
    "    #    P_filenames[i] = 'datasets/PROMISE/' + P_filenames[i] + '.txt'\r\n",
    "    #result, header = main(filename)\r\n",
    "    #output = write_results_S(header,result)\r\n",
    "    run(N_filenames, 'NASA.csv')\r\n",
    "    #print(header)\r\n",
    "    #print(result)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "datasets/NASA/MW1.arff.txt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b6c84498bf27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;31m#result, header = main(filename)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m#output = write_results_S(header,result)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NASA.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;31m#print(header)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;31m#print(result)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b6c84498bf27>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(datasets, savename)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/NASA/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b6c84498bf27>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \u001b[1;31m#print('*'*50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                 \u001b[0mauc_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b6c84498bf27>\u001b[0m in \u001b[0;36mevaluate_data\u001b[1;34m(model, model_name, X_test, y_test)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mauc_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_roc_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m#print(f\"Model Name: {model_name}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Monash University\\FIT3162 Computer Science Project 2\\Program\\Algorithm\\pf_eval\\AUC_ROC.ipynb\u001b[0m in \u001b[0;36mauc_roc_model\u001b[1;34m(model, X_test, y_test)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         return _average_binary_score(partial(_binary_roc_auc_score,\n\u001b[0m\u001b[0;32m    543\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    544\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    328\u001b[0m                          \"is not defined in that case.\")\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}